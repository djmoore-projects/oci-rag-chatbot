{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39bd8c01-2335-412f-a607-4de9fab5b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /Users/derekmoore/Desktop/OCI-GenAI-RAG-Project\n",
      "‚úÖ Success! Found 16 PDFs.\n",
      " - Danny Hsu TRANSCRIPT PODCAST.pdf\n",
      " - dylan milstein podcast transcript.pdf\n",
      " - kevin cahill podcast transcript.pdf\n",
      " - PODCAST SCRIPT Nico Pigni.pdf\n",
      " - Maria Lozada Podcast TRANSCRIPT.pdf\n",
      " - proptech_basics.pdf\n",
      " - Mike Russo TRANSCRIPT.pdf\n",
      " - mor milo pod transcript.pdf\n",
      " - Buddy Rushing WhiteFeather Investments PODCAST TRANSCRIPT.pdf\n",
      " - TRANSCRIPT OF PODCAST Leland Remias.pdf\n",
      " - TRANSCRIPT Alan Grosheider.pdf\n",
      " - Joseph El Am Prypco Podcast Transcript.pdf\n",
      " - greg offerd PODCAST TRANSCRIPT.pdf\n",
      " - PropTech_faq.pdf\n",
      " - Tom Gabrielle podcast TRANSCRIPT.pdf\n",
      " - PODCAST Transcript Josh Glasser Qwesty.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Check current directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Working Directory: {current_dir}\")\n",
    "\n",
    "# 2. List all PDF files\n",
    "try:\n",
    "    files = [f for f in os.listdir('.') if f.endswith('.pdf')]\n",
    "    print(f\"‚úÖ Success! Found {len(files)} PDFs.\")\n",
    "    for f in files:\n",
    "        print(f\" - {f}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Still blocked: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72dc9ac4-a74c-471f-9d55-af3b6a8b48b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16 files...\n",
      "Done with: Danny Hsu TRANSCRIPT PODCAST.pdf (38 chunks created)\n",
      "Done with: dylan milstein podcast transcript.pdf (31 chunks created)\n",
      "Done with: kevin cahill podcast transcript.pdf (30 chunks created)\n",
      "Done with: PODCAST SCRIPT Nico Pigni.pdf (33 chunks created)\n",
      "Done with: Maria Lozada Podcast TRANSCRIPT.pdf (30 chunks created)\n",
      "Done with: proptech_basics.pdf (5 chunks created)\n",
      "Done with: Mike Russo TRANSCRIPT.pdf (31 chunks created)\n",
      "Done with: mor milo pod transcript.pdf (46 chunks created)\n",
      "Done with: Buddy Rushing WhiteFeather Investments PODCAST TRANSCRIPT.pdf (48 chunks created)\n",
      "Done with: TRANSCRIPT OF PODCAST Leland Remias.pdf (27 chunks created)\n",
      "Done with: TRANSCRIPT Alan Grosheider.pdf (39 chunks created)\n",
      "Done with: Joseph El Am Prypco Podcast Transcript.pdf (29 chunks created)\n",
      "Done with: greg offerd PODCAST TRANSCRIPT.pdf (36 chunks created)\n",
      "Done with: PropTech_faq.pdf (6 chunks created)\n",
      "Done with: Tom Gabrielle podcast TRANSCRIPT.pdf (36 chunks created)\n",
      "Done with: PODCAST Transcript Josh Glasser Qwesty.pdf (31 chunks created)\n",
      "------------------------------\n",
      "‚úÖ FINAL TOTAL: 496 text chunks ready for the AI Database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Gather all your PDF names\n",
    "pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]\n",
    "\n",
    "all_chunks = []\n",
    "# We'll use a splitter to break the 16 PDFs into small \"searchable\" pieces\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "print(f\"Processing {len(pdf_files)} files...\")\n",
    "\n",
    "for pdf in pdf_files:\n",
    "    loader = PyPDFLoader(pdf)\n",
    "    data = loader.load()\n",
    "    # Break the pages into smaller 1000-character chunks\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    all_chunks.extend(chunks)\n",
    "    print(f\"Done with: {pdf} ({len(chunks)} chunks created)\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"‚úÖ FINAL TOTAL: {len(all_chunks)} text chunks ready for the AI Database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f7345cb-bda9-4093-9c91-06aca2dbd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ I can see the following models via API:\n",
      " - cohere.embed-v4.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyahw4vlsxm7newcqtlgmristnwxlrxox3h7bcnlomjpgwa)\n",
      " - cohere.embed-multilingual-light-image-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyanjovpmwmspjzwharl4tebjamhffc5brdqhvyvboarpyq)\n",
      " - cohere.embed-multilingual-image-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyazeracodio7mgnoq76vk26jdvdt7x7pa4amy3s6yomplq)\n",
      " - cohere.embed-english-image-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyaukpmlzyv2y3rb2sqdw4ldqsysxqula3wfnhadnj77drq)\n",
      " - cohere.embed-english-light-image-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceya56ycvdjfdwciqcgpzinzz72jre65z57rgyo4bvq7h55a)\n",
      " - cohere.embed-multilingual-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyaf4ga422xmco2gqbwaks7chwt24y6qtofhwwfrpxjxpxa)\n"
     ]
    }
   ],
   "source": [
    "import oci\n",
    "\n",
    "# Use the config dictionary we talked about earlier\n",
    "# Replace the placeholder OCIDs with your actual ones\n",
    "oci_config = {\n",
    "    \"user\": \"ocid1.user.oc1..aaaaaaaape6miicevicqskax5ixfjvughaatgvbkcv76dt6h2ukzkqgx2udq\", \n",
    "    \"fingerprint\": \"30:6e:74:f3:d6:c3:20:79:5e:36:c8:f9:86:bb:c3:7c\", \n",
    "    \"tenancy\": \"ocid1.tenancy.oc1..aaaaaaaapgfazp34bhifdky2itxmxrqvrcgzs2vr5limlz3fb7geh366gc3a\",\n",
    "    \"region\": \"us-ashburn-1\",\n",
    "    \"key_file\": \"/Users/derekmoore/ .oci/oci_api_key.pem\"\n",
    "}\n",
    "\n",
    "# This is the \"Truth Test\"\n",
    "gen_ai_client = oci.generative_ai.GenerativeAiClient(oci_config)\n",
    "try:\n",
    "    # We are asking OCI to list the models it sees for your account\n",
    "    models = gen_ai_client.list_models(compartment_id=oci_config[\"tenancy\"]).data\n",
    "    print(\"‚úÖ I can see the following models via API:\")\n",
    "    for m in models.items:\n",
    "        if \"embed\" in m.display_name.lower():\n",
    "            print(f\" - {m.display_name} (ID: {m.id})\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå API Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "25c81d13-ad99-4268-a979-f470cdedaa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings re-initialized with the direct OCID.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "# Use the specific OCID for Ashburn that your \"Truth Test\" previously found\n",
    "# This is the most bulletproof way to identify the model\n",
    "model_ocid = \"ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyahw4vlsxm7newcqtlgmristnwxlrxox3h7bcnlomjpgwa\"\n",
    "\n",
    "embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=model_ocid,\n",
    "    compartment_id=oci_config[\"tenancy\"], \n",
    "    client=gen_ai_inference_client \n",
    ")\n",
    "print(\"‚úÖ Embeddings re-initialized with the direct OCID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "749e72f4-4a87-44e5-b79b-b38adbe8ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to adb.us-ashburn-1.oraclecloud.com port 1521 [tcp/ncube-lm] succeeded!\n"
     ]
    }
   ],
   "source": [
    "!nc -v adb.us-ashburn-1.oraclecloud.com 1521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "badcd57e-6ba1-44d6-a768-7425af54471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Targeting wallet in: /Users/derekmoore/Documents/Oracle_Wallets/New_Wallet/Wallet_AssetsandAlgorithms\n",
      "‚úÖ CONNECTION SUCCESSFUL!\n",
      "Connected to: 23.26.0.1.0\n"
     ]
    }
   ],
   "source": [
    "import oracledb\n",
    "\n",
    "# 1. The EXACT subfolder where your .pem and .ora files live\n",
    "final_wallet_path = \"/Users/derekmoore/Documents/Oracle_Wallets/New_Wallet/Wallet_AssetsandAlgorithms\"\n",
    "\n",
    "# 2. Connection String\n",
    "dsn_string = \"\"\"(description=(address=(protocol=tcps)(port=1522)(host=adb.us-ashburn-1.oraclecloud.com))(connect_data=(service_name=ge6041e4e441a34_assetsandalgorithms_low.adb.oraclecloud.com))(security=(ssl_server_dn_match=yes)))\"\"\"\n",
    "\n",
    "try:\n",
    "    print(f\"üöÄ Targeting wallet in: {final_wallet_path}\")\n",
    "    conn = oracledb.connect(\n",
    "        user=\"ADMIN\",\n",
    "        password=\"4ssets&Algorithms\",\n",
    "        dsn=dsn_string,\n",
    "        wallet_location=final_wallet_path,\n",
    "        wallet_password=\"PropTech2026!\"\n",
    "    )\n",
    "    print(\"‚úÖ CONNECTION SUCCESSFUL!\")\n",
    "    print(f\"Connected to: {conn.version}\")\n",
    "except oracledb.Error as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "357487f7-46e1-4905-98a1-f1e2892d11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Table reset successfully for 384-dimensional 'Light' embeddings.\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "try:\n",
    "    # Safely clear the old 1024-dim table\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS PROPTECH_KNOWLEDGE PURGE\")\n",
    "    \n",
    "    # Create the new table with 384 dimensions for the Light model\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE PROPTECH_KNOWLEDGE (\n",
    "            id VARCHAR2(64) PRIMARY KEY,\n",
    "            text CLOB,\n",
    "            metadata JSON,\n",
    "            embedding VECTOR(384, FLOAT32)\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Table reset successfully for 384-dimensional 'Light' embeddings.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Table reset failed: {e}\")\n",
    "finally:\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08ac7903-7b24-4276-b0f9-fda5ba0edc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librarian re-initialized with: cohere.embed-english-light-v3.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "# Use the specific canonical name for the Light version\n",
    "# This model produces 384 dimensions\n",
    "model_id = \"cohere.embed-english-light-v3.0\" \n",
    "\n",
    "embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=model_id,\n",
    "    compartment_id=oci_config[\"tenancy\"],\n",
    "    client=gen_ai_inference_client \n",
    ")\n",
    "print(f\"‚úÖ Librarian re-initialized with: {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68bdb668-3caa-43ea-af04-a9a86eb9aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully re-routed to Chicago Inference Endpoint!\n"
     ]
    }
   ],
   "source": [
    "import oci\n",
    "from oci.generative_ai_inference import GenerativeAiInferenceClient\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "# 1. Update your region identifier\n",
    "oci_config[\"region\"] = \"us-chicago-1\"\n",
    "\n",
    "# 2. Update the Inference Service Endpoint for Chicago\n",
    "chicago_endpoint = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "# 3. Re-initialize the Inference Client pointing to Chicago\n",
    "gen_ai_inference_client = GenerativeAiInferenceClient(\n",
    "    oci_config, \n",
    "    service_endpoint=chicago_endpoint\n",
    ")\n",
    "\n",
    "# 4. Use the full Cohere English V3 model (1024 dims) now that we are in Chicago\n",
    "model_id = \"cohere.embed-english-v3.0\"\n",
    "\n",
    "embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=model_id,\n",
    "    compartment_id=oci_config[\"tenancy\"],\n",
    "    client=gen_ai_inference_client\n",
    ")\n",
    "print(\"‚úÖ Successfully re-routed to Chicago Inference Endpoint!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a73fad0-2236-4e18-bf34-1dce226fb3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Table reset for 1024-dimensional Chicago embeddings.\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS PROPTECH_KNOWLEDGE PURGE\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE PROPTECH_KNOWLEDGE (\n",
    "        id VARCHAR2(64) PRIMARY KEY,\n",
    "        text CLOB,\n",
    "        metadata JSON,\n",
    "        embedding VECTOR(1024, FLOAT32)\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"‚úÖ Table reset for 1024-dimensional Chicago embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "97cea7ee-1633-43d2-9b15-362269aa734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AI Librarian successfully re-routed to Chicago!\n"
     ]
    }
   ],
   "source": [
    "import oci\n",
    "from oci.generative_ai_inference import GenerativeAiInferenceClient\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "# 1. Target the Chicago Inference Endpoint\n",
    "chicago_endpoint = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "# 2. Re-initialize the Inference Client for the new region\n",
    "gen_ai_inference_client = GenerativeAiInferenceClient(\n",
    "    oci_config, \n",
    "    service_endpoint=chicago_endpoint\n",
    ")\n",
    "\n",
    "# 3. Setup the 1024-dimension Embeddings model\n",
    "# Chicago explicitly supports this model on-demand\n",
    "model_id = \"cohere.embed-english-v3.0\"\n",
    "\n",
    "embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=model_id,\n",
    "    compartment_id=oci_config[\"tenancy\"],\n",
    "    client=gen_ai_inference_client\n",
    ")\n",
    "print(\"‚úÖ AI Librarian successfully re-routed to Chicago!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "acaff23d-fb14-436f-987b-f250e9007742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database table ready for 1024-dimension Chicago vectors.\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "try:\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS PROPTECH_KNOWLEDGE PURGE\")\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE PROPTECH_KNOWLEDGE (\n",
    "            id VARCHAR2(64) PRIMARY KEY,\n",
    "            text CLOB,\n",
    "            metadata JSON,\n",
    "            embedding VECTOR(1024, FLOAT32)\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Database table ready for 1024-dimension Chicago vectors.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Table setup failed: {e}\")\n",
    "finally:\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4ea6dce4-1e11-4d76-b6b2-944ac7cdd98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ingesting 496 chunks into Oracle 23ai via Chicago...\n",
      "\n",
      "üèÜ MISSION ACCOMPLISHED!\n",
      "Successfully stored 496 vectors in your PropTech Knowledge Base.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import OracleVS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "try:\n",
    "    print(f\"üöÄ Ingesting {len(all_chunks)} chunks into Oracle 23ai via Chicago...\")\n",
    "    \n",
    "    # Connect Python to the table\n",
    "    vector_store = OracleVS(\n",
    "        client=conn,\n",
    "        embedding_function=embeddings,\n",
    "        table_name=\"PROPTECH_KNOWLEDGE\",\n",
    "        distance_strategy=DistanceStrategy.COSINE,\n",
    "        params={\"embedding_dim\": 1024} # Bypasses automatic API dimension checks\n",
    "    )\n",
    "    \n",
    "    # The actual data transfer\n",
    "    vector_store.add_documents(all_chunks)\n",
    "    print(\"\\nüèÜ MISSION ACCOMPLISHED!\")\n",
    "    print(f\"Successfully stored {len(all_chunks)} vectors in your PropTech Knowledge Base.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Final Ingestion Failed: {e}\")\n",
    "    print(\"üí° Tip: If you see a 401/Authentication error, re-run your oci_config cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a337c938-7fac-4853-8a46-5658c0ff807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-classic in /opt/anaconda3/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.5 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-classic) (1.2.6)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-classic) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-classic) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-classic) (2.12.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-classic) (6.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-classic) (2.32.5)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-classic) (2.0.43)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (25.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.5->langchain-classic) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (0.24.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (4.10.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b073593-3900-403a-bcd2-d60aed026672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chatbot converted to modern CHAT endpoint. Ready for Chicago!\n"
     ]
    }
   ],
   "source": [
    "# 1. New imports for the Chat-based OCI class\n",
    "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 2. Setup the \"Brain\" using the CHAT endpoint in Chicago\n",
    "# We use 'cohere.command-r-08-2024' as it is the stable on-demand standard\n",
    "llm = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-r-08-2024\", \n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=oci_config[\"tenancy\"],\n",
    "    client=gen_ai_inference_client,\n",
    "    model_kwargs={\"max_tokens\": 1000, \"temperature\": 0.7}\n",
    ")\n",
    "\n",
    "# 3. Re-initialize the Chain\n",
    "system_prompt = (\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, say that you don't know. \\n\\n {context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Re-link the modernized retrieval chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "qa_chain = create_retrieval_chain(vector_store.as_retriever(), question_answer_chain)\n",
    "\n",
    "print(\"‚úÖ Chatbot converted to modern CHAT endpoint. Ready for Chicago!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f979249d-3b2c-46eb-bbba-ec3509b3aa7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üè† PROPTECH AI KNOWLEDGE ASSISTANT (CHICAGO) ---\n",
      "I'm ready! Ask me anything about your podcast transcripts.\n",
      "(Type 'quit' or 'exit' to end the session)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is proptech\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: is short for Property Technology and refers to the use of digital technology to transform how real estate is bought, sold, managed, financed, and operated. It represents the intersection of real estate and modern technologies such as cloud computing, data analytics, artificial intelligence, automation, and software platforms. PropTech solutions aim to improve efficiency, transparency, decision-making, and user experience across the entire real estate lifecycle.\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Goodbye! Happy PropTech innovating!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"--- üè† PROPTECH AI KNOWLEDGE ASSISTANT (CHICAGO) ---\")\n",
    "print(\"I'm ready! Ask me anything about your podcast transcripts.\")\n",
    "print(\"(Type 'quit' or 'exit' to end the session)\\n\")\n",
    "\n",
    "while True:\n",
    "    # 1. Get user input\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    # 2. Check for exit command\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        print(\"AI: Goodbye! Happy PropTech innovating!\")\n",
    "        break\n",
    "        \n",
    "    if not user_input.strip():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # 3. Query the modernized Chicago chain\n",
    "        # The modern chain uses 'invoke' and returns a dictionary\n",
    "        result = qa_chain.invoke({\"input\": user_input})\n",
    "        \n",
    "        # 4. Print the answer\n",
    "        print(f\"\\nAI: {result['answer']}\\n\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        print(\"üí° Hint: If the connection timed out, re-run your 'conn' cell.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78029f-2644-46c4-9585-798277986979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
