{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39bd8c01-2335-412f-a607-4de9fab5b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /Users/derekmoore/Desktop/OCI-GenAI-RAG-Project\n",
      "✅ Success! Found 16 PDFs.\n",
      " - Danny Hsu TRANSCRIPT PODCAST.pdf\n",
      " - dylan milstein podcast transcript.pdf\n",
      " - kevin cahill podcast transcript.pdf\n",
      " - PODCAST SCRIPT Nico Pigni.pdf\n",
      " - Maria Lozada Podcast TRANSCRIPT.pdf\n",
      " - proptech_basics.pdf\n",
      " - Mike Russo TRANSCRIPT.pdf\n",
      " - mor milo pod transcript.pdf\n",
      " - Buddy Rushing WhiteFeather Investments PODCAST TRANSCRIPT.pdf\n",
      " - TRANSCRIPT OF PODCAST Leland Remias.pdf\n",
      " - TRANSCRIPT Alan Grosheider.pdf\n",
      " - Joseph El Am Prypco Podcast Transcript.pdf\n",
      " - greg offerd PODCAST TRANSCRIPT.pdf\n",
      " - PropTech_faq.pdf\n",
      " - Tom Gabrielle podcast TRANSCRIPT.pdf\n",
      " - PODCAST Transcript Josh Glasser Qwesty.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Check current directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Working Directory: {current_dir}\")\n",
    "\n",
    "# 2. List all PDF files\n",
    "try:\n",
    "    files = [f for f in os.listdir('.') if f.endswith('.pdf')]\n",
    "    print(f\"✅ Success! Found {len(files)} PDFs.\")\n",
    "    for f in files:\n",
    "        print(f\" - {f}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Still blocked: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72dc9ac4-a74c-471f-9d55-af3b6a8b48b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16 files...\n",
      "Done with: Danny Hsu TRANSCRIPT PODCAST.pdf (38 chunks created)\n",
      "Done with: dylan milstein podcast transcript.pdf (31 chunks created)\n",
      "Done with: kevin cahill podcast transcript.pdf (30 chunks created)\n",
      "Done with: PODCAST SCRIPT Nico Pigni.pdf (33 chunks created)\n",
      "Done with: Maria Lozada Podcast TRANSCRIPT.pdf (30 chunks created)\n",
      "Done with: proptech_basics.pdf (5 chunks created)\n",
      "Done with: Mike Russo TRANSCRIPT.pdf (31 chunks created)\n",
      "Done with: mor milo pod transcript.pdf (46 chunks created)\n",
      "Done with: Buddy Rushing WhiteFeather Investments PODCAST TRANSCRIPT.pdf (48 chunks created)\n",
      "Done with: TRANSCRIPT OF PODCAST Leland Remias.pdf (27 chunks created)\n",
      "Done with: TRANSCRIPT Alan Grosheider.pdf (39 chunks created)\n",
      "Done with: Joseph El Am Prypco Podcast Transcript.pdf (29 chunks created)\n",
      "Done with: greg offerd PODCAST TRANSCRIPT.pdf (36 chunks created)\n",
      "Done with: PropTech_faq.pdf (6 chunks created)\n",
      "Done with: Tom Gabrielle podcast TRANSCRIPT.pdf (36 chunks created)\n",
      "Done with: PODCAST Transcript Josh Glasser Qwesty.pdf (31 chunks created)\n",
      "------------------------------\n",
      "✅ FINAL TOTAL: 496 text chunks ready for the AI Database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Gather all your PDF names\n",
    "pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]\n",
    "\n",
    "all_chunks = []\n",
    "# We'll use a splitter to break the 16 PDFs into small \"searchable\" pieces\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "print(f\"Processing {len(pdf_files)} files...\")\n",
    "\n",
    "for pdf in pdf_files:\n",
    "    loader = PyPDFLoader(pdf)\n",
    "    data = loader.load()\n",
    "    # Break the pages into smaller 1000-character chunks\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    all_chunks.extend(chunks)\n",
    "    print(f\"Done with: {pdf} ({len(chunks)} chunks created)\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"✅ FINAL TOTAL: {len(all_chunks)} text chunks ready for the AI Database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7345cb-bda9-4093-9c91-06aca2dbd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ I can see the following models via API:\n",
      " - cohere.embed-v4.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyahw4vlsxm7newcqtlgmristnwxlrxox3h7bcnlomjpgwa)\n",
      " - cohere.embed-multilingual-light-image-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyanjovpmwmspjzwharl4tebjamhffc5brdqhvyvboarpyq)\n",
      " - cohere.embed-multilingual-image-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyazeracodio7mgnoq76vk26jdvdt7x7pa4amy3s6yomplq)\n",
      " - cohere.embed-english-image-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyaukpmlzyv2y3rb2sqdw4ldqsysxqula3wfnhadnj77drq)\n",
      " - cohere.embed-english-light-image-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceya56ycvdjfdwciqcgpzinzz72jre65z57rgyo4bvq7h55a)\n",
      " - cohere.embed-multilingual-v3.0 (ID: ocid1.generativeaimodel.oc1.iad.amaaaaaask7dceyaf4ga422xmco2gqbwaks7chwt24y6qtofhwwfrpxjxpxa)\n"
     ]
    }
   ],
   "source": [
    "import oci\n",
    "\n",
    "# Use the config dictionary we talked about earlier\n",
    "# Replace the placeholder OCIDs with your actual ones\n",
    "oci_config = {\n",
    "    \"user\": \"ocid1.user.oc1..aaaaaaaape6miicevicqskax5ixfjvughaatgvbkcv76dt6h2ukzkqgx2udq\", \n",
    "    \"fingerprint\": \"30:6e:74:f3:d6:c3:20:79:5e:36:c8:f9:86:bb:c3:7c\", \n",
    "    \"tenancy\": \"ocid1.tenancy.oc1..aaaaaaaapgfazp34bhifdky2itxmxrqvrcgzs2vr5limlz3fb7geh366gc3a\",\n",
    "    \"region\": \"us-ashburn-1\",\n",
    "    \"key_file\": \"/Users/derekmoore/ .oci/oci_api_key.pem\"\n",
    "}\n",
    "\n",
    "# This is the \"Truth Test\"\n",
    "gen_ai_client = oci.generative_ai.GenerativeAiClient(oci_config)\n",
    "try:\n",
    "    # We are asking OCI to list the models it sees for your account\n",
    "    models = gen_ai_client.list_models(compartment_id=oci_config[\"tenancy\"]).data\n",
    "    print(\"✅ I can see the following models via API:\")\n",
    "    for m in models.items:\n",
    "        if \"embed\" in m.display_name.lower():\n",
    "            print(f\" - {m.display_name} (ID: {m.id})\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ API Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c81d13-ad99-4268-a979-f470cdedaa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TOTAL SUCCESS! The Librarian is finally authenticated via direct client injection.\n"
     ]
    }
   ],
   "source": [
    "import oci\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "# 1. Your verified credentials dictionary\n",
    "oci_config = {\n",
    "    \"user\": \"ocid1.user.oc1..aaaaaaaape6miicevicqskax5ixfjvughaatgvbkcv76dt6h2ukzkqgx2udq\", \n",
    "    \"fingerprint\": \"30:6e:74:f3:d6:c3:20:79:5e:36:c8:f9:86:bb:c3:7c\", \n",
    "    \"tenancy\": \"ocid1.tenancy.oc1..aaaaaaaapgfazp34bhifdky2itxmxrqvrcgzs2vr5limlz3fb7geh366gc3a\",\n",
    "    \"region\": \"us-ashburn-1\",\n",
    "    \"key_file\": \"/Users/derekmoore/ .oci/oci_api_key.pem\"\n",
    "}\n",
    "\n",
    "# 2. Manually create the OCI Client using your dictionary\n",
    "# This ensures we don't trigger the file-search logic in LangChain\n",
    "gen_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(\n",
    "    config=oci_config,\n",
    "    service_endpoint=\"https://inference.generativeai.us-ashburn-1.oci.oraclecloud.com\"\n",
    ")\n",
    "\n",
    "# 3. Pass the CLIENT directly to LangChain\n",
    "# By passing 'client', LangChain skips its own internal authentication logic\n",
    "embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=\"cohere.embed-v4.0\",\n",
    "    compartment_id=oci_config[\"tenancy\"],\n",
    "    client=gen_ai_inference_client  # <-- This is the master key\n",
    ")\n",
    "\n",
    "print(\"✅ TOTAL SUCCESS! The Librarian is finally authenticated via direct client injection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008d65b-dda6-4116-8cc6-099244350866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "\n",
    "# 1. Path to your UNZIPPED wallet folder\n",
    "wallet_path = \"/Users/derekmoore/Documents/Oracle_Wallets/Wallet_AssetsandAlgorithms\"\n",
    "\n",
    "# 2. Establish connection in THIN MODE with the password provided\n",
    "# Replace 'YOUR_WALLET_PASSWORD' with the actual password you set in OCI\n",
    "conn = oracledb.connect(\n",
    "    user=\"ADMIN\",\n",
    "    password=\"4ssets&Algorithms\",\n",
    "    dsn=\"assetsandalgorithms_low\",\n",
    "    config_dir=wallet_path,\n",
    "    wallet_location=wallet_path,\n",
    "    wallet_password=\"assetsunzip1\"  # <-- ADD THIS LINE\n",
    ")\n",
    "\n",
    "print(\"✅ SUCCESS! No more manual password prompts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1c2c7-af5d-4969-b88e-1641354344d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
